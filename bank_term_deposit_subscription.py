# -*- coding: utf-8 -*-
"""Bank Term Deposit Subscription.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bSOK5y3t_IURKb63MXXKPSKk24Kc0J0Q
"""

# import libraries

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from imblearn.over_sampling import RandomOverSampler
from sklearn.metrics import classification_report

import pickle

# Load dataset

data = pd.read_csv('bank-full.csv', sep=';')

# Inspect the data

data.shape

data.head()

data.info()

data.describe()

# Missing Values

data.isna().sum()

# Exploratory Data Analysis (EDA)

# Checking for outliers

plt.figure(figsize=(12,8))
sns.boxplot(data = data)

# Let us answer the following question
# 1. How many clients of the bank have default a loan
# 2. How many clients of the bank per education level?
# 3. How many clients of the nak per marital status
# 4. How many clients of the bank per job/role/position?
# 5. How many clients of the bank subscribed to the term deposit?

plt.figure(figsize=(10, 6))
sns.countplot(y='default', data=data, order = data['default'].value_counts().index)
plt.title('Number of Bank Clients that have defaulted a loan')
plt.xlabel('Number of Clients')
plt.ylabel('Loan Default')
plt.show()

list_education = data['education'].unique()
list_education

plt.figure(figsize=(10, 6))
sns.countplot(y='education', data=data, order = data['education'].value_counts().index)
plt.title('Number of Bank Clients per Educational Level')
plt.xlabel('Number of Clients')
plt.ylabel('Educational Level')
plt.show()

plt.figure(figsize=(10, 6))
sns.countplot(y='marital', data=data, order = data['marital'].value_counts().index)
plt.title('Number of Bank Clients per Marital Status')
plt.xlabel('Number of Clients')
plt.ylabel('Marital Status')
plt.show()

list_job = data['job'].unique()
list_job

plt.figure(figsize=(10, 6))
sns.countplot(y='job', data=data, order = data['job'].value_counts().index)
plt.title('Number of Bank Clients per Job Title')
plt.xlabel('Number of Clients')
plt.ylabel('Job Title')
plt.show()

plt.figure(figsize=(10, 6))
sns.countplot(y='y', data=data, order = data['y'].value_counts().index)
plt.title('Number of Bank Clients subscribed to term deposit')
plt.xlabel('Number of Clients')
plt.ylabel('Term Deposit Status')
plt.show()

# Correlation between the attributes

numeric_df = data.select_dtypes(include=np.number)
correlation = numeric_df.corr()
plt.figure(figsize=(12,8))
sns.heatmap(correlation, annot=True, cmap='coolwarm')

## Feature Engineering

# Find out how many clients have negative or zero balance and drop records of those clients

negative_or_zero_balance_clients = (data['balance'] <= 0).sum()
print(f"Number of clients with a negative or zero balance: {negative_or_zero_balance_clients}")

data = data[data['balance'] > 0]
print(f"Shape of the dataframe after dropping: {data.shape}")

#normalize thw balance and call duration columns

data['balance'] = np.log(data['balance'] + 1)

sns.distplot(data['balance'])

data['duration'] = np.log(data['duration'] + 1)

sns.distplot(data['duration'])

# label encode attributes

cols = ['default', 'housing', 'loan', 'y']
le = LabelEncoder()
for col in cols:
	data[col] = le.fit_transform(data[col])

data['contacted_before'] = (data['previous'] > 0).astype(int)
data['contacted_recently'] = (data['pdays'] != -1).astype(int)
data['poutcome'] = data['poutcome'].apply(lambda x: 0 if x in ['failure', 'unknown', 'other'] else 1)

# introduce new columns is_employed, is_married, is_graduate

data['is_employed'] = data['job'].apply(lambda x: 0 if x in ['retired', 'student', 'unemployed', 'unknown'] else 1)
data['is_married'] = data['marital'].apply(lambda x: 0 if x in ['single', 'divorced'] else 1)
data['is_graduate'] = data['education'].apply(lambda x: 0 if x in ['secondary', 'primary', 'unknown'] else 1)

# drop the following columns, age, job, marital, education, contact, day, month, campaign, pdays,previous

data = data.drop(['age', 'job', 'marital', 'education', 'contact', 'day', 'month', 'campaign', 'pdays', 'previous'], axis=1)
data.head()

#split data into independent and dependent trainig dataset

X = data.drop(columns = ['y'], axis = 1)
y = data['y']


X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.20,random_state=42)

#Logistics regression
model1 = LogisticRegression()
model1.fit(X_train,y_train)
y_pred_model1 = model1.predict(X_test)
accuracy = accuracy_score(y_test,y_pred_model1)

print(accuracy*100)

score = cross_val_score(model1,X,y,cv=5)
score

#Check average score
print(np.mean(score)*100)

#Random Forest Classifier
model2 = RandomForestClassifier()
model2.fit(X_train,y_train)
y_pred_model2 = model2.predict(X_test)
accuracy = accuracy_score(y_test,y_pred_model2)
print(accuracy*100)

# confusion matrix Logistics Regression
cm = confusion_matrix(y_test, y_pred_model1)
print("Confusion Matrix for Logistic Regression:")
print(cm)

# Confusion matrix Random Forest Classifier
cm_rf = confusion_matrix(y_test, y_pred_model2)
print("Confusion Matrix for Random Forest Classifier:")
print(cm_rf)

oversample = RandomOverSampler(random_state = 42)
X_resampled, y_resampled = oversample.fit_resample(X,y)

data_resampled = pd.concat([pd.DataFrame(X_resampled, columns=X.columns), pd.Series(y_resampled, name='y')], axis=1)
# print(X_resampled, y_resampled)

X_resampled_train, X_resampled_test, y_resampled_train, y_resampled_test = train_test_split(X_resampled,y_resampled,test_size = 0.2,random_state=42)

#Logistics regression
model1 = LogisticRegression()
model1.fit(X_resampled_train,y_resampled_train)
y_pred_model1 = model1.predict(X_resampled_test)
accuracy = accuracy_score(y_resampled_test,y_pred_model1)
print(accuracy*100)

#Random Forest Classifier
model2 = RandomForestClassifier()
model2.fit(X_resampled_train,y_resampled_train)
y_pred_model2 = model2.predict(X_resampled_test)
accuracy = accuracy_score(y_resampled_test,y_pred_model2)
print(accuracy*100)

# confusion matrix Logisics Regression
cm = confusion_matrix(y_resampled_test,y_pred_model1)
print("Confusion Matrix for Logistic Regression:")
print(cm)

#Confusion matrix Random Forest Classifier
cm_rf = confusion_matrix(y_resampled_test,y_pred_model2)
print("Confusion Matrix for Random Forest Classifier:")
print(cm_rf)

def generate_classification_report(model_name, y_test, y_pred):
	report = classification_report(y_test,y_pred)
	print(f"Classification Report For {model_name}: \n{report}\n")
generate_classification_report(model1,y_resampled_test,y_pred_model1)
generate_classification_report(model2,y_resampled_test,y_pred_model2)

with open('random_forest_model.pkl', 'wb') as file:
    pickle.dump(model2, file)

